# On Binary Data Analysis/对二元数据的分析
> William Wang --- Dept. Combined Interdisciplines and Engineering

## Preface

从直观上看，对于这份社区数据集，可以总结出如下特点：
 - 它拥有较多的变量，并且所有变量都具有单一的特征：即所有关于这些变量的数据都只由0或者1构成。也就是说，我们面对的是一个二元数据集。
 - 这个数据集由两个部分组成，一部分是对于交易类别的记录，另一部分是对于app栏目浏览类别的记录，对于出现过以上行为的用户，在对应的类别变量里记为1，没有则记为0.
 - 这两部分数据，既互相独立，又互相关联，所以在处理时应铭记这一点。
 
## 对于聚类分析方法的选择与考虑

传统的聚类算法多种多样，而目前的主流是计算向量距离为核心的聚类算法，如K-means，K-modes以及Hierarchial clustering等等。对于这种二元数据集，在实际应用的过程中，主流算法暴露出了原理上的缺陷。尽管最后可以得出较符合聚类思路的结果，但是我们依旧有理由质疑其精度与普适性。

以简单的K-means聚类为例，当我们把整个一行数据写作向量，并且计算其均值，比较其距离的时候，由于0和1的存在，这种均值并没有多大意义。而聚类完成的向量依旧是一个二元向量（即永远为0和1组成）。这种距离的计算对于二元数据的向量难以产生效果。

基于以上的原因，有两种思路产生了，第一种是先用一种方法变动数据，再进行K-means等算法分析，第二种是直接换用基于不同原理的算法。我将在这份报告中讨论这两种思路。

第一种思路的执行方案是，先通过MCA分析，基本处理数据，然后通过k-means聚类。

第二种思路的执行方案是，放弃以距离计算作为原理的聚类方法，改为以条件概率作为计算依据，依靠这种原理的聚类算法的代表，就是LCA聚类（Latent Class Analysis）和LPA聚类（Latent Profile Analysis）。在这里我们采用LCA聚类方法。

LCA分析，即潜在类别分析，是通过条件概率公式，反推出具有相似条件概率的聚类，相比于距离计算更加适合变量较多的二元数据集。潜在变量是离散的，通过条件概率计算出的结果指示出变量对于特定值的可能性。

首先，我们会预先设定LCA的聚类数量，然后算法会根据每个用户表现出这些聚类行为的概率大小（即条件概率），将用户归属到这些聚类当中，这样，我们不仅能够进行普通的聚类，更能分析每个单独用户的行为，以及这名用户属于那一类


## 使用MCA再进行K-means的聚类分析方法

## 使用LCA模型的聚类分析方法

按照前文所叙的思路，我们现在将要实现这个模型。

python中没有直接进行LCA模型分析的库，一方面是LCA模型比较小众，另一方面是因为对于LCA模型涉及到的条件概率计算来说，python并非最好的选择。这个时候我们需要用到另一种数据分析软件 - R/RStudio以及R Package DepMixS4 (v. 1.4.0)

```
depmixS4: Dependent Mixture Models - Hidden Markov Models of GLMs and Other Distributions in S4
URL: https://cran.r-project.org/web/packages/depmixS4/index.html
官方文档：https://www.rdocumentation.org/packages/depmixS4/versions/1.4-0

```

R Package DepMixS4是设计用于潜在马尔可夫模型类的建模处理的，因此LCA模型用它来做非常合适。

* 此处应该注意，当没有连接VPN时，这个package无法安装。我们有理由相信，大量像DepMixS4这样不错的package因为这个原因无法出现在大众的视野当中，倘若这些package能够被利用起来，R的用处在国内应该会更大。

### Get Started!

首先，安装并Library DepMixS4 Package：

```{r}
install.packages("depmixS4")
library("depmixS4")
```

对于这个LCA模型，我们需要预设潜在的class数量，也就是说，我们需要设定有多少种类型的用户，建模会围绕这个数量展开。这一步代码如下：

```
#model 1 with class = 6 / 设定Model 1拥有6种潜在客户类型

lca <- read.table("community_related_lca.csv", sep=",") #读取csv数据集

names(lca) <- c( "cash_n", "zf_n", "cf_n", "zz_n" ,"cc_n", "jf_n", "dk_n","sz_pv","zz_pv","zh_pv", "chc_pv",  "lc_pv","jj_pv",xd_pv","sh_pv","hd_pv") #将全部变量名称写入向量之中。

summary(lca) # 输出对数据集的大致描述。
```

其中，summary(lca)的输出结果是这样：

![r_output_1](https://github.com/cwang122/CMB/blob/master/r_output_screenshot.png)

图片中的xxx_n和xxx_pv即是指上面代码中names()里的16中变量，意指用户表现出的16种行为。0为没有表现，1为曾经表现过。不难看出，大多数变量的0都远远超过1的数量，这种数据集即可被形容为“sparse”（稀疏的）数据集。

> "Sparse" in binary dataset, means there are few 1s, with an ocean of 0s.  --- Anonymous on ResearchGate

> 二元数据集里的所谓“稀疏”，即意味着少部分的1，和汪洋大海一般的0. --- ResearchGate上某位老哥

### 关于LCA聚类的快速Q&A~

Q: 你们并不知道这些人中有几种类型的用户，和具体的用户偏好以及背景，强行设定聚类数量的话，如何解释聚类结果并且保证其正确呢？

A：如同大多数问卷调查一样，从心理学到社会学，都并非事先知道用户的属性，而是通过归纳的方法得出。严格来说，聚类的终极形态，是把每一个用户归为一类，这样是最为精确，最为自然的。聚类正是为了有目的地模糊个体之间的差异而做出的一种妥协，聚类是否有效，是否能够解释，取决于算法的输出结果是否在各变量间拥有足够大的差异，以及在数据所拥有的背景情境下能否说得通。

Q: 聚类数量设定多少算合适呢？

A: 和上面的回答相似，只要在具体环境下，这个聚类的行为概率构成可以被解释的通，并且每个用户对于不同行为聚类发生概率的差异足够明显就可以了。这个设定完全处于实际情境的需要。

### 建立模型

当数据集成功被导入，并且我们对其有一个大致了解后，便可以建立模型了。

```
mod1 <- mix(list(cash_n~1, zf_n~1, cf_n~1, zz_n~1,cc_n~1,jf_n~1,dk_n~1,sz_pv~1,zz_pv~1,zh_pv~1,chc_pv~1, lc_pv~1,jj_pv~1,xd_pv~1,sh_pv~1,hd_pv~1),
             data=lca, # the dataset to use
             nstates=3, # the number of latent classes
             family=list(multinomial("identity"), multinomial("identity"), multinomial("identity"),
                         multinomial("identity"),multinomial("identity"),multinomial("identity"),
                         multinomial("identity"),multinomial("identity"),multinomial("identity"),
                         multinomial("identity"),multinomial("identity"),multinomial("identity"),
                         multinomial("identity"),multinomial("identity"),multinomial("identity"),
                         multinomial("identity")),
             respstart=runif(144))

fmod1 <- fit(mod1, verbose=FALSE)
summary(fmod1)
```

***如果对所使用函数有任何疑问，请对应上面package中的官方文档。

其中，mix函数即为模型函数，list()包含了模型中的16种变量，对应底下family的数量。这个函数中关键的变量有两个：nstates=(),和respstart(),第一个是人为输入的聚类数量，第二种是模型中的参数总数，这个总数如果输入不对的话，算法会自动提醒你正确的数量，因此不用担心。

fit()即是建模函数，summary是我们想看的输出结果。

当设定的聚类数量越多，聚类函数所需要的时间也会快速增加，从3个聚类约花5分钟到16个聚类约花1.5小时左右不等。

结果如下：

```
> fmod1 <- fit(mod1, verbose=FALSE)
converged at iteration 93 with logLik: -379670.9 
```

函数在第93个循环的时候达成收敛，log of likelihood为-379670.9。这里值得一提的是，log of likelihood越低，代表模型精确度越高，这个通常是和聚类的数量成正比例联系在一起的。一个很好的问题是，我们能否找到一个聚类数量的最优解，也就是说，当聚类数量取这个值的时候，log of likelihood最大。

答案是：尽管log of likelihood有着数学意义，但是其并不一定具有实际意义。当聚类数量的数学最优解可以取0-65000中的任何一个数时，我们又该怎么去解释它们呢？

在这样的思考下，数学意义在此刻显得不太重要了。

### 最终模型输出

```
 summary(fmod1)
Mixture probabilities model 
      pr1       pr2       pr3 
0.1947598 0.5757254 0.2295148 

Response parameters 
Resp 1 : multinomial 
Resp 2 : multinomial 
Resp 3 : multinomial 
Resp 4 : multinomial 
Resp 5 : multinomial 
Resp 6 : multinomial 
Resp 7 : multinomial 
Resp 8 : multinomial 
Resp 9 : multinomial 
Resp 10 : multinomial 
Resp 11 : multinomial 
Resp 12 : multinomial 
Resp 13 : multinomial 
Resp 14 : multinomial 
Resp 15 : multinomial 
Resp 16 : multinomial 
        Re1.1      Re1.2        Re1.3     Re2.1     Re2.2        Re2.3     Re3.1      Re3.2        Re3.3     Re4.1      Re4.2        Re4.3     Re5.1      Re5.2        Re5.3     Re6.1       Re6.2        Re6.3     Re7.1
St1 0.9628617 0.03713835 0.000000e+00 0.6756977 0.3243023 0.000000e+00 0.6215929 0.37840706 0.000000e+00 0.7465637 0.25343631 0.000000e+00 0.9506427 0.04935732 0.000000e+00 0.9942183 0.005781702 0.000000e+00 0.9960425
St2 0.9872603 0.01271316 2.650359e-05 0.7453401 0.2546334 2.650359e-05 0.9759250 0.02404845 2.650359e-05 0.9873024 0.01267113 2.650359e-05 0.9779499 0.02202360 2.650359e-05 0.9983036 0.001669927 2.650359e-05 0.9961137
St3 0.9570323 0.04296767 0.000000e+00 0.5015671 0.4984329 0.000000e+00 0.8451795 0.15482053 0.000000e+00 0.1858446 0.81415543 0.000000e+00 0.9069209 0.09307908 0.000000e+00 0.9959980 0.004002003 0.000000e+00 0.9751450
          Re7.2        Re7.3     Re8.1     Re8.2        Re8.3     Re9.1      Re9.2        Re9.3    Re10.1    Re10.2       Re10.3    Re11.1      Re11.2       Re11.3    Re12.1     Re12.2       Re12.3    Re13.1
St1 0.003957462 0.000000e+00 0.7180465 0.2819535 0.000000e+00 0.8254610 0.17453901 0.000000e+00 0.0911274 0.9088726 0.000000e+00 0.3638807 0.636119271 0.000000e+00 0.5744050 0.42559499 0.000000e+00 0.7306164
St2 0.003859768 2.650359e-05 0.8981651 0.1018083 2.650359e-05 0.9893556 0.01061786 2.650359e-05 0.7433173 0.2566562 2.650359e-05 0.9980294 0.001944133 2.650359e-05 0.9658331 0.03414035 2.650359e-05 0.9828308
St3 0.024854994 0.000000e+00 0.6652654 0.3347346 0.000000e+00 0.4028113 0.59718870 0.000000e+00 0.4125232 0.5874768 0.000000e+00 0.9884745 0.011525493 0.000000e+00 0.9762218 0.02377817 0.000000e+00 0.9869136
        Re13.2       Re13.3    Re14.1     Re14.2       Re14.3    Re15.1    Re15.2       Re15.3    Re16.1    Re16.2       Re16.3
St1 0.26938359 0.000000e+00 0.9139126 0.08608739 0.000000e+00 0.6612212 0.3387788 0.000000e+00 0.4748739 0.5251261 0.000000e+00
St2 0.01714273 2.650359e-05 0.8657028 0.13427067 2.650359e-05 0.7190167 0.2809568 2.650359e-05 0.5554977 0.4444758 2.650359e-05
St3 0.01308644 0.000000e+00 0.7924361 0.20756386 0.000000e+00 0.6691685 0.3308315 0.000000e+00 0.6077509 0.3922491 0.000000e+00

```

输出结果显示模型中一共有16个变量，对应用户数据集中的16种行为。


      pr1       pr2       pr3 
0.1947598 0.5757254 0.2295148 

这里pr1是第一个聚类的人数所占总人数的比例，为19.47%，相似的，第二个聚类的占比为57.57%，而第三个聚类为22.95%。这个也能够通过概率理论的角度来解释，即随机选取一位客户，他分别属于三种用户的概率如pr1, pr2, pr3所示。

如何解读这三种聚类呢？在下面的输出结果中，我们便可以找到答案。

底下这部分令人眼花缭乱结果是由16个下面的输出结果构成的。St1, St2, St3表示预设的3种聚类。Re1.1表示特定聚类用户在第一个变量里选0的概率，Re1.2表示这类用户选1的概率， Re1.3无意义并且无限趋近于0。那么结果中的0.9628617，即为第一种聚类中的用户选0的概率，0.01271316即为第二种聚类用户选1的概率

 Re1.1      Re1.2        Re1.3     
St1 0.9628617 0.03713835 0.000000e+00
St2 0.9872603 0.01271316 2.650359e-05 
St3 0.9570323 0.04296767 0.000000e+00







