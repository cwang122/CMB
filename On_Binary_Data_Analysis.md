# On Binary Data Analysis/对二元数据的分析
> William Wang --- Dept. Combined Interdisciplines and Engineering

## Preface

从直观上看，对于这份社区数据集，可以总结出如下特点：
 - 它拥有较多的变量，并且所有变量都具有单一的特征：即所有关于这些变量的数据都只由0或者1构成。也就是说，我们面对的是一个二元数据集。
 - 这个数据集由两个部分组成，一部分是对于交易类别的记录，另一部分是对于app栏目浏览类别的记录，对于出现过以上行为的用户，在对应的类别变量里记为1，没有则记为0.
 - 这两部分数据，既互相独立，又互相关联，所以在处理时应铭记这一点。
 
## 对于聚类分析方法的选择与考虑

传统的聚类算法多种多样，而目前的主流是计算向量距离为核心的聚类算法，如K-means，K-modes以及Hierarchial clustering等等。对于这种二元数据集，在实际应用的过程中，主流算法暴露出了原理上的缺陷。尽管最后可以得出较符合聚类思路的结果，但是我们依旧有理由质疑其精度与普适性。

以简单的K-means聚类为例，当我们把整个一行数据写作向量，并且计算其均值，比较其距离的时候，由于0和1的存在，这种均值并没有多大意义。而聚类完成的向量依旧是一个二元向量（即永远为0和1组成）。这种距离的计算对于二元数据的向量难以产生效果。

基于以上的原因，有两种思路产生了，第一种是先用一种方法变动数据，再进行K-means等算法分析，第二种是直接换用基于不同原理的算法。我将在这份报告中讨论这两种思路。

第一种思路的执行方案是，先通过MCA分析，基本处理数据，然后通过k-means聚类。

第二种思路的执行方案是，放弃以距离计算作为原理的聚类方法，改为以条件概率作为计算依据，依靠这种原理的聚类算法的代表，就是LCA聚类（Latent Class Analysis）和LPA聚类（Latent Profile Analysis）。在这里我们采用LCA聚类方法。

LCA分析，即潜在类别分析，是通过条件概率公式，反推出具有相似条件概率的聚类，相比于距离计算更加适合变量较多的二元数据集。潜在变量是离散的，通过条件概率计算出的结果指示出变量对于特定值的可能性。

首先，我们会预先设定LCA的聚类数量，然后算法会根据每个用户表现出这些聚类行为的概率大小（即条件概率），将用户归属到这些聚类当中，这样，我们不仅能够进行普通的聚类，更能分析每个单独用户的行为，以及这名用户属于那一类


## 使用MCA再进行K-means的聚类分析方法

## 使用LCA模型的聚类分析方法

按照前文所叙的思路，我们现在将要实现这个模型。

python中没有直接进行LCA模型分析的库，一方面是LCA模型比较小众，另一方面是因为对于LCA模型涉及到的条件概率计算来说，python并非最好的选择。这个时候我们需要用到另一种数据分析软件 - R/RStudio以及R Package DepMixS4 (v. 1.4.0)

```
depmixS4: Dependent Mixture Models - Hidden Markov Models of GLMs and Other Distributions in S4
URL: https://cran.r-project.org/web/packages/depmixS4/index.html
官方文档：https://www.rdocumentation.org/packages/depmixS4/versions/1.4-0

```

R Package DepMixS4是设计用于潜在马尔可夫模型类的建模处理的，因此LCA模型用它来做非常合适。

* 此处应该注意，当没有连接VPN时，这个package无法安装。我们有理由相信，大量像DepMixS4这样不错的package因为这个原因无法出现在大众的视野当中，倘若这些package能够被利用起来，R的用处在国内应该会更大。

### Get Started!

首先，安装并Library DepMixS4 Package：

```{r}
install.packages("depmixS4")
library("depmixS4")
```

对于这个LCA模型，我们需要预设潜在的class数量，也就是说，我们需要设定有多少种类型的用户，建模会围绕这个数量展开。这一步代码如下：

```
#model 1 with class = 6 / 设定Model 1拥有6种潜在客户类型

lca <- read.table("community_related_lca.csv", sep=",") #读取csv数据集

names(lca) <- c( "cash_n", "zf_n", "cf_n", "zz_n" ,"cc_n", "jf_n", "dk_n","sz_pv","zz_pv","zh_pv", "chc_pv",  "lc_pv","jj_pv",xd_pv","sh_pv","hd_pv") #将全部变量名称写入向量之中。

summary(lca) # 输出对数据集的大致描述。
```

其中，summary(lca)的输出结果是这样：

![r_output_1](https://github.com/cwang122/CMB/blob/master/r_output_screenshot.png)

图片中的xxx_n和xxx_pv即是指上面代码中names()里的16种变量，意指用户表现出的16种行为。0为没有表现，1为曾经表现过。不难看出，大多数变量的0都远远超过1的数量，这种数据集即可被形容为“sparse”（稀疏的）数据集。

> "Sparse" in binary dataset, means there are few 1s, with an ocean of 0s.  --- Anonymous on ResearchGate

> 二元数据集里的所谓“稀疏”，即意味着少部分的1，和汪洋大海一般的0. --- ResearchGate上某位不具名人士

### 关于LCA聚类的快速Q&A~

Q: 你们并不知道这些人中有几种类型的用户，和具体的用户偏好以及背景，强行设定聚类数量的话，如何解释聚类结果并且保证其正确呢？

A：如同大多数问卷调查一样，从心理学到社会学，都并非事先知道用户的属性，而是通过归纳的方法得出。严格来说，聚类的终极形态，是把每一个用户归为一类，这样是最为精确，最为自然的。聚类正是为了有目的地模糊个体之间的差异而做出的一种妥协，聚类是否有效，是否能够解释，取决于算法的输出结果是否在各变量间拥有足够大的差异，以及在数据所拥有的背景情境下能否说得通。

Q: 聚类数量设定多少算合适呢？

A: 和上面的回答相似，只要在具体环境下，这个聚类的行为概率构成可以被解释的通，并且每个用户对于不同行为聚类发生概率的差异足够明显就可以了。这个设定完全处于实际情境的需要。

### 建立模型

当数据集成功被导入，并且我们对其有一个大致了解后，便可以建立模型了。

```
mod1 <- mix(list(cash_n~1, zf_n~1, cf_n~1, zz_n~1,cc_n~1,jf_n~1,dk_n~1,sz_pv~1,zz_pv~1,zh_pv~1,chc_pv~1, lc_pv~1,jj_pv~1,xd_pv~1,sh_pv~1,hd_pv~1),
             data=lca, # the dataset to use
             nstates=3, # the number of latent classes
             family=list(multinomial("identity"), multinomial("identity"), multinomial("identity"),
                         multinomial("identity"),multinomial("identity"),multinomial("identity"),
                         multinomial("identity"),multinomial("identity"),multinomial("identity"),
                         multinomial("identity"),multinomial("identity"),multinomial("identity"),
                         multinomial("identity"),multinomial("identity"),multinomial("identity"),
                         multinomial("identity")),
             respstart=runif(144))

fmod1 <- fit(mod1, verbose=FALSE)
summary(fmod1)
```

***如果对所使用函数有任何疑问，请对应此package中的官方文档。

> 官方文档：https://www.rdocumentation.org/packages/depmixS4/versions/1.4-0


其中，mix函数即为模型函数，list()包含了模型中的16种变量，对应底下family的数量。这个函数中关键的变量有两个：nstates=(),和respstart(),第一个是人为输入的聚类数量，第二种是模型中的参数总数，这个总数如果输入不对的话，算法会自动提醒你正确的数量，因此不用担心。

fit()即是建模函数，summary是我们想看的输出结果。

当设定的聚类数量越多，聚类函数所需要的时间也会快速增加，从3个聚类约花5分钟到16个聚类约花1.5小时左右不等。

结果如下：

```
> fmod1 <- fit(mod1, verbose=FALSE)
converged at iteration 93 with logLik: -379670.9 
```

函数在第93个循环的时候达成收敛，log of likelihood为-379670.9。这里值得一提的是，log of likelihood（为负值）越大，代表模型精确度越高，这个通常是和聚类的数量成正比例联系在一起的。一个很好的问题是，我们能否找到一个聚类数量的最优解，也就是说，当聚类数量取这个值的时候，log of likelihood最大。

答案是：尽管log of likelihood有着数学意义，但是其并不一定具有实际意义。65000条数据可以选择聚类2-65000个，而当聚类数量的数学最优解真的取了0-65000中的任何一个数时，我们又该怎么去解释它们呢？

在这样的思考下，数学意义在此刻显得不太重要了。

### 最终模型输出

```
 summary(fmod1)
Mixture probabilities model 
      pr1       pr2       pr3 
0.1947598 0.5757254 0.2295148 

Response parameters 
Resp 1 : multinomial 
Resp 2 : multinomial 
Resp 3 : multinomial 
Resp 4 : multinomial 
Resp 5 : multinomial 
Resp 6 : multinomial 
Resp 7 : multinomial 
Resp 8 : multinomial 
Resp 9 : multinomial 
Resp 10 : multinomial 
Resp 11 : multinomial 
Resp 12 : multinomial 
Resp 13 : multinomial 
Resp 14 : multinomial 
Resp 15 : multinomial 
Resp 16 : multinomial 
        Re1.1      Re1.2        Re1.3     Re2.1     Re2.2        Re2.3     Re3.1      Re3.2        Re3.3     Re4.1      Re4.2        Re4.3     Re5.1      Re5.2        Re5.3     Re6.1       Re6.2        Re6.3     Re7.1
St1 0.9628617 0.03713835 0.000000e+00 0.6756977 0.3243023 0.000000e+00 0.6215929 0.37840706 0.000000e+00 0.7465637 0.25343631 0.000000e+00 0.9506427 0.04935732 0.000000e+00 0.9942183 0.005781702 0.000000e+00 0.9960425
St2 0.9872603 0.01271316 2.650359e-05 0.7453401 0.2546334 2.650359e-05 0.9759250 0.02404845 2.650359e-05 0.9873024 0.01267113 2.650359e-05 0.9779499 0.02202360 2.650359e-05 0.9983036 0.001669927 2.650359e-05 0.9961137
St3 0.9570323 0.04296767 0.000000e+00 0.5015671 0.4984329 0.000000e+00 0.8451795 0.15482053 0.000000e+00 0.1858446 0.81415543 0.000000e+00 0.9069209 0.09307908 0.000000e+00 0.9959980 0.004002003 0.000000e+00 0.9751450
          Re7.2        Re7.3     Re8.1     Re8.2        Re8.3     Re9.1      Re9.2        Re9.3    Re10.1    Re10.2       Re10.3    Re11.1      Re11.2       Re11.3    Re12.1     Re12.2       Re12.3    Re13.1
St1 0.003957462 0.000000e+00 0.7180465 0.2819535 0.000000e+00 0.8254610 0.17453901 0.000000e+00 0.0911274 0.9088726 0.000000e+00 0.3638807 0.636119271 0.000000e+00 0.5744050 0.42559499 0.000000e+00 0.7306164
St2 0.003859768 2.650359e-05 0.8981651 0.1018083 2.650359e-05 0.9893556 0.01061786 2.650359e-05 0.7433173 0.2566562 2.650359e-05 0.9980294 0.001944133 2.650359e-05 0.9658331 0.03414035 2.650359e-05 0.9828308
St3 0.024854994 0.000000e+00 0.6652654 0.3347346 0.000000e+00 0.4028113 0.59718870 0.000000e+00 0.4125232 0.5874768 0.000000e+00 0.9884745 0.011525493 0.000000e+00 0.9762218 0.02377817 0.000000e+00 0.9869136
        Re13.2       Re13.3    Re14.1     Re14.2       Re14.3    Re15.1    Re15.2       Re15.3    Re16.1    Re16.2       Re16.3
St1 0.26938359 0.000000e+00 0.9139126 0.08608739 0.000000e+00 0.6612212 0.3387788 0.000000e+00 0.4748739 0.5251261 0.000000e+00
St2 0.01714273 2.650359e-05 0.8657028 0.13427067 2.650359e-05 0.7190167 0.2809568 2.650359e-05 0.5554977 0.4444758 2.650359e-05
St3 0.01308644 0.000000e+00 0.7924361 0.20756386 0.000000e+00 0.6691685 0.3308315 0.000000e+00 0.6077509 0.3922491 0.000000e+00

```

输出结果显示模型中一共有16个变量，对应用户数据集中的16种行为。

```

      pr1       pr2       pr3 
0.1947598 0.5757254 0.2295148 

```

这里pr1是第一个聚类的人数所占总人数的比例，为19.47%，相似的，第二个聚类的占比为57.57%，而第三个聚类为22.95%。这个也能够通过概率理论的角度来解释，即随机选取一位客户，他分别属于三种用户的概率如pr1, pr2, pr3所示。

如何解读这三种聚类呢？在下面的输出结果中，我们便可以找到答案。

上面那部分令人眼花缭乱的小数结果是由16个下面的输出结果构成的。St1, St2, St3表示预设的3种聚类。Re1.1表示特定聚类用户在第一个变量里选0的概率，Re1.2表示这类用户选1的概率， Re1.3无意义且无限趋近于0。那么解释起来，结果中的0.9628617，即为第一种聚类中的用户选0的概率，0.03713835即为第一种聚类用户选1的概率，两者相加为1，符合概率论的定义。

```
 Re1.1      Re1.2        Re1.3     
St1 0.9628617 0.03713835 0.000000e+00
St2 0.9872603 0.01271316 2.650359e-05 
St3 0.9570323 0.04296767 0.000000e+00

```

> 解读：聚类1用户有3%的概率表现变量1行为，聚类2用户有1%的概率表现出变量1行为，聚类3用户则有4%的概率表现出变量1行为。

> 或者从另一个角度看：96%的聚类1用户没有表现变量1行为，98%的聚类2用户没有表现变量1行为，95%的聚类3用户没有表现变量1行为。（但不建议这样解读）


为了完全解读这份输出结果，我们可以这样描绘：

![r_output_2](https://github.com/cwang122/CMB/blob/master/s_1.jpg)

这张图上，所有用户被聚类成了三组，分别为Class 1，Class 2和Class 3。我们分别记为第一类用户，第二类用户和第三类用户。

图表中的数字是该类用户表现出第1-16种行为的概率，根据概率计算的原理，也是该类用户中表现出该种行为的用户占总数的比值。其中，(0.0, 0.2)被标记为紫色，意为几乎没有用户表现此种行为。(0.2, 0.5)被标记为蓝色，意为部分用户表现出了此种行为。(0.5, 1)被标记为橙色，意为大多数用户倾向于表现出这种行为。

那么，从图表上看：

第一种用户占人群的20%，他们中的部分（25%-32%）会进行支付类，财富类和转账类交易。在app浏览信息方面，28%的用户会进行收支上的浏览，他们中的几乎所有人（90%）会进行总览页面的浏览。63%的人会进行持仓收益的浏览，26%-40%的人会进行理财和基金页面的浏览。这个数据和他们前面的转账和理财交易相呼应。值得一提的是，三分之一以上甚至超过一半的人会进行生活频道以及抽奖页面的浏览。这类人我们可以赋名为“情调型用户”

第二种用户占人群的57%。他们中的约25%会进行支付类交易，但并没有财富与转账，app的页面也并没有怎么浏览，13%的人会看看信贷，25-28%的人会浏览总览和生活页面，约44%的人会浏览活动抽奖页面，他们非常的佛系，独立于消费的世界之外，偶尔会抽奖。我们暂且把他们赋名为“佛系用户”，这类用户占人群的大多数。

第三类用户占人群的23%，49%的人会发生支付交易，81%的人会发生转账类交易，相对应的，59%和58%的人会浏览转账与总览页面，但是相比前面的两类人，他们对于生活频道和活动页面的浏览却不太热衷（分别为33%和39%）。


我们并不满足于聚类，会想知道进一步的，更具体的结果，在R中写入：

```
posterior.states <- depmixS4::posterior(fmod1) # Saving Class Assignments
head(round(posterior.states, 3)) # show the first 6 cases, rounded to 3 decimal places to match IDRE output

```

这两行代码会输出每一个用户的这三种聚类行为模式中的占比（比如某一位用户可能有80%的第一类用户，15%的第二类用户和5%的第三类用户），并且为每一位用户做如下的标记。

```
输出：

  state    S1    S2    S3
1     2 0.000 1.000 0.000
2     1 0.912 0.001 0.087
3     2 0.002 0.993 0.006
4     1 0.972 0.025 0.004
5     3 0.013 0.169 0.817
6     2 0.002 0.993 0.005

```

这份表格左边标明了用户ID（重新编号由1开始），state表示他们的归属的最终聚类，S1, S2, S3是第一二三类用户。而底下的数字代表他们归属于这类用户的概率，程序会取三种概率中的最大值，将这个用户归属到拥有最大概率的那一类当中。这三个概率数字的和加起来是1.

比如：

```
  state    S1    S2    S3
2     1 0.912 0.001 0.087
```
这行结果的意思是，用户2属于第一类用户，（因为）他有0.912的概率表现出第一类用户的行为，但是只有0.1%和8.7%的概率表现出第二种用户行为和第三种用户的行为。所以程序将他归类到第一类用户当中，因此state（状态）将他标记为1（第一类用户）。


### 评估聚类的效果与准确度

以上的这个占比结构分析还会使用户拥有另一种功能，那就是衡量聚类的效果，

读者们请试想，如果大多数用户的三种聚类属性概率差别不大，比如如下情况：

```
  state    S1    S2    S3
2     1    0.4  0.3   0.3
```
我们虽然看到用户2最多表现的是第一类聚类（0.4概率），但是0.4和其他两种聚类的概率差别不大，仅有0.1的差距。因此我们很难说将用户2归因到第一类用户是最合理的行为 --- 事实上，我们更应该说他几乎均衡地表现了三种用户的所有特征。

那么，如果在预设聚类数字变动（一般是增加），发现有这种均匀分布而非极化的特征后，我们应该意识到：第一，聚类数量过多，部分聚类特征已经开始重叠，我们的聚类已经非常细化。第二，此时应该找出具有相似特征的聚类，人工进行合并。

## 伟大的尝试，n = 10 ！

我们不断增加n，也就是聚类的数量，这会导致运行时间的增加。

n = 10的时候，我们设定了10个聚类，代码如下：

```

install.packages("depmixS4")
library("depmixS4")

#model 1 with class = 10
lca <- read.table("community_related_lca.csv", sep=",")
names(lca) <- c( "cash_n", "zf_n", "cf_n", "zz_n" ,"cc_n", "jf_n", "dk_n","sz_pv","zz_pv","zh_pv", "chc_pv", "lc_pv","jj_pv","xd_pv","sh_pv","hd_pv")
summary(lca)

mod1 <- mix(list(cash_n~1, zf_n~1, cf_n~1, zz_n~1,cc_n~1,jf_n~1,dk_n~1,sz_pv~1,zz_pv~1,zh_pv~1,chc_pv~1, lc_pv~1,jj_pv~1,xd_pv~1,sh_pv~1,hd_pv~1),
             data=lca, # the dataset to use
             nstates=10, # the number of latent classes
             family=list(multinomial("identity"), multinomial("identity"), multinomial("identity"),
                         multinomial("identity"),multinomial("identity"),multinomial("identity"),
                         multinomial("identity"),multinomial("identity"),multinomial("identity"),
                         multinomial("identity"),multinomial("identity"),multinomial("identity"),
                         multinomial("identity"),multinomial("identity"),multinomial("identity"),
                         multinomial("identity")),
             respstart=runif(720))

fmod1 <- fit(mod1, verbose=FALSE)
summary(fmod1)

posterior.states <- depmixS4::posterior(fmod1) # Saving Class Assignments
head(round(posterior.states, 3)) # show the first 6 cases, rounded to 3 decimal places to match IDRE output

posterior.states$state <- as.factor(posterior.states$state)
summary(posterior.states$state) # how many people in each latent class?

fmod1@npars #the total number of parameters of the model

#输出聚类结果到csv文件当中

df <- data.frame(posterior.states)
View(df)

round_df <- format(df, digit = 3)

View(round_df)

write.csv(df,'LCA_Dataframe_R_Output.csv')

```
运行了约2小时后：

输出结果如下，让我们马上来解读。

```
> summary(fmod1)
Mixture probabilities model 
       pr1        pr2        pr3        pr4        pr5        pr6        pr7        pr8        pr9       pr10 
0.07823183 0.13352987 0.03845103 0.04678478 0.08570954 0.10097629 0.31824448 0.02849610 0.04735902 0.12221705 

Response parameters 
Resp 1 : multinomial 
Resp 2 : multinomial 
Resp 3 : multinomial 
Resp 4 : multinomial 
Resp 5 : multinomial 
Resp 6 : multinomial 
Resp 7 : multinomial 
Resp 8 : multinomial 
Resp 9 : multinomial 
Resp 10 : multinomial 
Resp 11 : multinomial 
Resp 12 : multinomial 
Resp 13 : multinomial 
Resp 14 : multinomial 
Resp 15 : multinomial 
Resp 16 : multinomial 
         Re1.1       Re1.2        Re1.3     Re2.1     Re2.2        Re2.3     Re3.1      Re3.2        Re3.3      Re4.1       Re4.2        Re4.3     Re5.1       Re5.2        Re5.3     Re6.1
St1  0.9890255 0.010974459 0.0000000000 0.6386872 0.3613128 0.0000000000 0.9628509 0.03714907 0.0000000000 0.91714496 0.082855036 0.0000000000 0.9691232 0.030876798 0.0000000000 0.9980304
St2  0.9449632 0.055036798 0.0000000000 0.3847254 0.6152746 0.0000000000 0.7811789 0.21882113 0.0000000000 0.68611844 0.313881560 0.0000000000 0.9513153 0.048684656 0.0000000000 0.9957513
St3  0.9584909 0.041509131 0.0000000000 0.6959942 0.3040058 0.0000000000 0.4032646 0.59673543 0.0000000000 0.07261358 0.927386419 0.0000000000 0.9276999 0.072300141 0.0000000000 0.9922878
St4  0.9755094 0.024490579 0.0000000000 0.6250821 0.3749179 0.0000000000 1.0000000 0.00000000 0.0000000000 0.85755188 0.142448122 0.0000000000 0.9719598 0.028040151 0.0000000000 0.9958555
St5  0.9961553 0.003666661 0.0001780291 0.8680841 0.1317379 0.0001780291 0.9998220 0.00000000 0.0001780291 0.99329183 0.006530137 0.0001780291 0.9507086 0.049113357 0.0001780291 0.9998220
St6  0.9539966 0.046003392 0.0000000000 0.6052319 0.3947681 0.0000000000 0.8954390 0.10456096 0.0000000000 0.08636184 0.913638159 0.0000000000 0.9651171 0.034882910 0.0000000000 0.9962399
St7  0.9929206 0.007079401 0.0000000000 0.8157630 0.1842370 0.0000000000 1.0000000 0.00000000 0.0000000000 0.97852607 0.021473932 0.0000000000 0.9922014 0.007798616 0.0000000000 0.9986923
St8  0.9752746 0.024725376 0.0000000000 0.4974089 0.5025911 0.0000000000 0.9308309 0.06916911 0.0000000000 0.18650045 0.813499549 0.0000000000 0.5725423 0.427457651 0.0000000000 0.9962248
St9  0.9410069 0.058993063 0.0000000000 0.2614929 0.7385071 0.0000000000 0.4446797 0.55532029 0.0000000000 0.46641284 0.533587161 0.0000000000 0.9157941 0.084205853 0.0000000000 0.9944744
St10 0.9774690 0.022530963 0.0000000000 0.7919968 0.2080032 0.0000000000 0.7612588 0.23874124 0.0000000000 0.96157659 0.038423412 0.0000000000 0.9651060 0.034894010 0.0000000000 0.9948533
           Re6.2        Re6.3     Re7.1        Re7.2        Re7.3      Re8.1      Re8.2        Re8.3      Re9.1       Re9.2        Re9.3     Re10.1    Re10.2       Re10.3    Re11.1
St1  0.001969644 0.0000000000 0.9993533 0.0006467493 0.0000000000 0.94301253 0.05698747 0.0000000000 0.97684321 0.023156795 0.0000000000 0.80371988 0.1962801 0.0000000000 1.0000000
St2  0.004248682 0.0000000000 0.9866733 0.0133267128 0.0000000000 0.81727870 0.18272130 0.0000000000 0.99852258 0.001477425 0.0000000000 0.44037170 0.5596283 0.0000000000 1.0000000
St3  0.007712156 0.0000000000 0.9896127 0.0103872759 0.0000000000 0.59761110 0.40238890 0.0000000000 0.29620158 0.703798424 0.0000000000 0.04049603 0.9595040 0.0000000000 0.2503750
St4  0.004144517 0.0000000000 0.9841383 0.0158616609 0.0000000000 0.03802452 0.96197548 0.0000000000 0.86595647 0.134043533 0.0000000000 0.27248303 0.7275170 0.0000000000 1.0000000
St5  0.000000000 0.0001780291 0.9866306 0.0131913545 0.0001780291 0.93524600 0.06457597 0.0001780291 0.96651036 0.033311607 0.0001780291 0.79476444 0.2050575 0.0001780291 0.9998220
St6  0.003760140 0.0000000000 0.9882070 0.0117929881 0.0000000000 0.70466036 0.29533964 0.0000000000 0.01214685 0.987853151 0.0000000000 0.44336042 0.5566396 0.0000000000 1.0000000
St7  0.001307669 0.0000000000 1.0000000 0.0000000000 0.0000000000 0.96736806 0.03263194 0.0000000000 0.98279056 0.017209440 0.0000000000 0.81984273 0.1801573 0.0000000000 1.0000000
St8  0.003775166 0.0000000000 0.8929451 0.1070549136 0.0000000000 0.61587489 0.38412511 0.0000000000 0.48378684 0.516213164 0.0000000000 0.38981089 0.6101891 0.0000000000 0.9852539
St9  0.005525594 0.0000000000 0.9986959 0.0013040936 0.0000000000 0.56814043 0.43185957 0.0000000000 0.65291593 0.347084074 0.0000000000 0.09490724 0.9050928 0.0000000000 0.7835122
St10 0.005146731 0.0000000000 0.9976103 0.0023897448 0.0000000000 0.80462794 0.19537206 0.0000000000 0.97873750 0.021262501 0.0000000000 0.12264503 0.8773550 0.0000000000 0.2786741
         Re11.2       Re11.3    Re12.1     Re12.2       Re12.3    Re13.1      Re13.2       Re13.3     Re14.1      Re14.2       Re14.3      Re15.1    Re15.2       Re15.3     Re16.1
St1  0.00000000 0.0000000000 0.9539923 0.04600772 0.0000000000 0.9674618 0.032538204 0.0000000000 0.91055724 0.089442764 0.0000000000 0.005952886 0.9940471 0.0000000000 0.05421384
St2  0.00000000 0.0000000000 0.9835103 0.01648973 0.0000000000 0.9911331 0.008866931 0.0000000000 0.91839426 0.081605743 0.0000000000 0.819938608 0.1800614 0.0000000000 0.63671899
St3  0.74962497 0.0000000000 0.4522193 0.54778068 0.0000000000 0.7396229 0.260377102 0.0000000000 0.90229229 0.097707711 0.0000000000 0.718283983 0.2817160 0.0000000000 0.54194188
St4  0.00000000 0.0000000000 0.9654703 0.03452966 0.0000000000 0.9870534 0.012946618 0.0000000000 0.77224404 0.227755956 0.0000000000 0.586449534 0.4135505 0.0000000000 0.65408212
St5  0.00000000 0.0001780291 0.9812597 0.01856226 0.0001780291 0.9906645 0.009157475 0.0001780291 0.33393796 0.665884009 0.0001780291 0.718084488 0.2817375 0.0001780291 0.76571812
St6  0.00000000 0.0000000000 0.9805525 0.01944750 0.0000000000 0.9884548 0.011545164 0.0000000000 0.92157866 0.078421335 0.0000000000 0.761673536 0.2383265 0.0000000000 0.69936256
St7  0.00000000 0.0000000000 0.9624526 0.03754737 0.0000000000 0.9844359 0.015564072 0.0000000000 0.99535230 0.004647698 0.0000000000 0.867155901 0.1328441 0.0000000000 0.58493564
St8  0.01474613 0.0000000000 0.9817228 0.01827722 0.0000000000 0.9857201 0.014279898 0.0000000000 0.08177142 0.918228578 0.0000000000 0.640135464 0.3598645 0.0000000000 0.71707549
St9  0.21648777 0.0000000000 0.8198814 0.18011859 0.0000000000 0.8780836 0.121916415 0.0000000000 0.80915645 0.190843551 0.0000000000 0.130531329 0.8694687 0.0000000000 0.02974416
St10 0.72132588 0.0000000000 0.5502480 0.44975200 0.0000000000 0.6898426 0.310157424 0.0000000000 0.93677386 0.063226145 0.0000000000 0.756551248 0.2434488 0.0000000000 0.54692309
        Re16.2       Re16.3
St1  0.9457862 0.0000000000
St2  0.3632810 0.0000000000
St3  0.4580581 0.0000000000
St4  0.3459179 0.0000000000
St5  0.2341039 0.0001780291
St6  0.3006374 0.0000000000
St7  0.4150644 0.0000000000
St8  0.2829245 0.0000000000
St9  0.9702558 0.0000000000
St10 0.4530769 0.0000000000
> 
> posterior.states <- depmixS4::posterior(fmod1) # Saving Class Assignments
> head(round(posterior.states, 3)) # show the first 6 cases, rounded to 3 decimal places to match IDRE output
  state    S1    S2    S3    S4    S5    S6    S7    S8    S9   S10
1     5 0.000 0.000 0.000 0.000 1.000 0.000 0.000 0.000 0.000 0.000
2     9 0.000 0.135 0.209 0.000 0.000 0.001 0.000 0.000 0.596 0.057
3     7 0.000 0.038 0.000 0.001 0.083 0.000 0.875 0.000 0.000 0.002
4    10 0.000 0.000 0.002 0.000 0.000 0.000 0.000 0.000 0.000 0.998
5     2 0.004 0.814 0.000 0.001 0.001 0.011 0.156 0.004 0.007 0.001
6     7 0.002 0.033 0.000 0.000 0.038 0.000 0.924 0.000 0.000 0.003
> 
> posterior.states$state <- as.factor(posterior.states$state)
> summary(posterior.states$state) # how many people in each latent class?
    1     2     3     4     5     6     7     8     9    10 
 6794  7073  2320  3605  3914  6971 22922  1615  2774  7548 
> 
> fmod1@npars #the total number of parameters of the model
[1] 490
> 
> df <- summary(posterior.states)
> View(df)
> df <- summary(posterior.states)
> View(df)
> df <- data.frame(posterior.states)
> View(df)


```

对于多种聚类，我们通常采用的办法是将其中差别不大的几类合并起来，这样的合并需要对这其中的差别有一个数量上的规定和分析人员直观的认识。当我们意识到某两类或者多类聚类拥有某种共同的特征，而他们之间的差异却又不那么大的时候，我们就可以将它们合并成一类。

聚类的结果如下：

![r_output_3](https://github.com/cwang122/CMB/blob/master/IMG_2334.jpeg)

和前文所述相同，图表中的数字是该类用户表现出第1-16种行为的概率，根据概率计算的原理，也是该类用户中表现出该种行为的用户占总数的比值。其中，(0.0, 0.2)被标记为紫色，意为几乎没有用户表现此种行为。(0.2, 0.6)被标记为蓝色，意为部分用户表现出了此种行为。(0.6, 1)被标记为橙色，意为大多数用户倾向于表现出这种行为。

同时我们对这10个聚类做出了解释：

![r_output_4](https://github.com/cwang122/CMB/blob/master/IMG_2331.jpeg)


我们从这里可以发现，当聚类数量大于10的时候，他们依然有着可以被解释的意义。












